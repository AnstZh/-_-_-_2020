{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание выполнили студентки БММ181: Желткова Анастасия, Карпулова Алина, Прохожева Диана, Шелепова Юлия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание: \n",
    "\n",
    "Используя train_test_split из sklearn.model_selection разбить датасет на две части: X_test (содержит информацию о пользователе и фильме), y_test (оценка) и аналогичные X_train, y_train. Далее задача предсказать y_train. Метрика качества (стандартная Mean squared error)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная задача нацелена на предсказание рейтинга фильмов. \n",
    "Тем самым нашей основной метрикой будет RMSE, а не MSE, так как мы сразу видим нашу ошибку исходя из рейтинга. \n",
    "\n",
    "\n",
    "Мы очень долго думали,каким же способом было бы легче и удобнее строить модели, для прогнозирования рейтинга фильмов. Изучив различные библиотеки и алгоритмы, мы наткнулись на библиотеку Surprise. Ее расшифровка - Simple Python RecommendatIon System Engine. То есть по сути нам нет нужды самим прописывать и продумывать сложные алгоритмы, когда уже все готово. Зачем придумывать велосипед. Наша главная задача в данной ситуации, была разобраться в документации библиотеки и понять, как ее использовать в наших целях.\n",
    "\n",
    "\n",
    "После изучения документации, мы остановились на следующих моделях\n",
    "\n",
    "Модели, которые использовали для предсказания рейтинга:\n",
    "\n",
    "\n",
    "SVD - Метод сингулярных разложений матриц, один из самых популярных в построении рекомендаций.\n",
    "\n",
    "SVD++ - Алгоритм SVD ++, расширение SVD с учетом неявных рейтингов.\n",
    "\n",
    "KNNWithMeans - Основной алгоритм коллаборативной фильтрации, учитывающий средние оценки каждого пользователя.\n",
    "\n",
    "KNNBasic - Основной алгоритм коллаборативной фильтрации.\n",
    "\n",
    "KNNBaseline - Основной алгоритм коллаборативной фильтрации с учетом базового рейтинга.\n",
    "\n",
    "NMF - Алгоритм коллаборативной  фильтрации, основанный на неотрицательной матричной факторизации.\n",
    "\n",
    "SlopeOne - Простой, но точный алгоритм коллаборативной фильтрации.\n",
    "\n",
    "KNNWithZScore - Основной алгоритм коллаборативной фильтрации с учетом нормализация z-показателя каждого пользователя.\n",
    "\n",
    "Более подробную информацию об этих моделях и как они работают можно прочитать в документации библиотеки surprise.\n",
    "\n",
    "Также мы думали воспользоваться библиотекой reco.recommender, но к сожалению при закгрузке ее через терминал в аканоду выходили ошибки. Но изучив ее, можно сказать, что он могла быть удобнее и лучше, чем библиотека surprise.\n",
    "\n",
    "\n",
    "\n",
    "Ссылка на библиотеку Surprise - http://surpriselib.com/\n",
    "\n",
    "Ссылка на reco.recommender - https://github.com/mayukh18/reco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сперва мы подгружаем часть библиотек, которые нам точно понадобятся и уже походу задания будем добавлять новые."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт необходимых библиотек\n",
    "from surprise import Reader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем мы загружем наши данные по информации о пользователях, фильмах и их рейтинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"ratings.csv\")\n",
    "tags= pd.read_csv(\"tags.csv\")\n",
    "movies = pd.read_csv(\"movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.merge(ratings, on = 'movieId', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы создаем датасет, который необходим нам, чтобы предсказывать оценку. Для рекомендательной системы используются 3 переменные- userid , movieid и rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100806</th>\n",
       "      <td>596</td>\n",
       "      <td>188301</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100807</th>\n",
       "      <td>318</td>\n",
       "      <td>188675</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100808</th>\n",
       "      <td>212</td>\n",
       "      <td>188751</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100809</th>\n",
       "      <td>514</td>\n",
       "      <td>188797</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100810</th>\n",
       "      <td>318</td>\n",
       "      <td>188833</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100811</th>\n",
       "      <td>338</td>\n",
       "      <td>189043</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100812</th>\n",
       "      <td>338</td>\n",
       "      <td>189111</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100813</th>\n",
       "      <td>184</td>\n",
       "      <td>189333</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100814</th>\n",
       "      <td>248</td>\n",
       "      <td>189333</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100815</th>\n",
       "      <td>318</td>\n",
       "      <td>189381</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100816</th>\n",
       "      <td>210</td>\n",
       "      <td>189547</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100817</th>\n",
       "      <td>462</td>\n",
       "      <td>189713</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100818</th>\n",
       "      <td>50</td>\n",
       "      <td>190183</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100819</th>\n",
       "      <td>338</td>\n",
       "      <td>190207</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100820</th>\n",
       "      <td>338</td>\n",
       "      <td>190209</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100821</th>\n",
       "      <td>338</td>\n",
       "      <td>190213</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100822</th>\n",
       "      <td>338</td>\n",
       "      <td>190215</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100823</th>\n",
       "      <td>338</td>\n",
       "      <td>190219</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100824</th>\n",
       "      <td>338</td>\n",
       "      <td>190221</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100825</th>\n",
       "      <td>184</td>\n",
       "      <td>191005</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100826</th>\n",
       "      <td>184</td>\n",
       "      <td>193565</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100827</th>\n",
       "      <td>184</td>\n",
       "      <td>193567</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100828</th>\n",
       "      <td>184</td>\n",
       "      <td>193571</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100829</th>\n",
       "      <td>184</td>\n",
       "      <td>193573</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100830</th>\n",
       "      <td>184</td>\n",
       "      <td>193579</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>184</td>\n",
       "      <td>193581</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>184</td>\n",
       "      <td>193583</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>184</td>\n",
       "      <td>193585</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>184</td>\n",
       "      <td>193587</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>331</td>\n",
       "      <td>193609</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating\n",
       "0            1        1     4.0\n",
       "1            5        1     4.0\n",
       "2            7        1     4.5\n",
       "3           15        1     2.5\n",
       "4           17        1     4.5\n",
       "5           18        1     3.5\n",
       "6           19        1     4.0\n",
       "7           21        1     3.5\n",
       "8           27        1     3.0\n",
       "9           31        1     5.0\n",
       "10          32        1     3.0\n",
       "11          33        1     3.0\n",
       "12          40        1     5.0\n",
       "13          43        1     5.0\n",
       "14          44        1     3.0\n",
       "15          45        1     4.0\n",
       "16          46        1     5.0\n",
       "17          50        1     3.0\n",
       "18          54        1     3.0\n",
       "19          57        1     5.0\n",
       "20          63        1     5.0\n",
       "21          64        1     4.0\n",
       "22          66        1     4.0\n",
       "23          68        1     2.5\n",
       "24          71        1     5.0\n",
       "25          73        1     4.5\n",
       "26          76        1     0.5\n",
       "27          78        1     4.0\n",
       "28          82        1     2.5\n",
       "29          86        1     4.0\n",
       "...        ...      ...     ...\n",
       "100806     596   188301     4.0\n",
       "100807     318   188675     3.5\n",
       "100808     212   188751     4.5\n",
       "100809     514   188797     4.0\n",
       "100810     318   188833     4.5\n",
       "100811     338   189043     2.5\n",
       "100812     338   189111     3.0\n",
       "100813     184   189333     4.0\n",
       "100814     248   189333     3.5\n",
       "100815     318   189381     2.5\n",
       "100816     210   189547     1.0\n",
       "100817     462   189713     2.5\n",
       "100818      50   190183     3.5\n",
       "100819     338   190207     1.5\n",
       "100820     338   190209     4.0\n",
       "100821     338   190213     1.0\n",
       "100822     338   190215     1.5\n",
       "100823     338   190219     1.0\n",
       "100824     338   190221     1.0\n",
       "100825     184   191005     4.5\n",
       "100826     184   193565     3.5\n",
       "100827     184   193567     3.0\n",
       "100828     184   193571     4.0\n",
       "100829     184   193573     4.0\n",
       "100830     184   193579     3.5\n",
       "100831     184   193581     4.0\n",
       "100832     184   193583     3.5\n",
       "100833     184   193585     3.5\n",
       "100834     184   193587     3.5\n",
       "100835     331   193609     4.0\n",
       "\n",
       "[100836 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = movies.groupby(by=['userId','movieId'], as_index=False, sort=False).mean()\n",
    "df = df[['userId','movieId','rating']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сперва мы бы хотели проверить наивный прогноз, а что если все остальные оценки будут одинаковыми. Насколько сильно будет велика наша ошибка?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"rating\"]\n",
    "\n",
    "df = df.drop(['rating'], axis=1)\n",
    "features = list(df.columns)\n",
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test ,y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.5028326, 3.5028326, 3.5028326, 3.5028326, 3.5028326])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "y_mean = np.mean(y_train)                     # посчитали среднее \n",
    "y_pred_naive = np.ones(len(y_test)) * y_mean  # спрогнозировали\n",
    "y_pred_naive[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.04475933055856"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "rmse = math.sqrt(mse(y_test, y_pred_naive))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, наивный прогноз - в данной ситуации это одна из худших моделей. Но теперь мы можем узнать разницу между сложными алгоритмами и обычным наивным прогнозом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заново загружем данные, так как мы удалили колонку рейтинг из датасета для наивного прогноза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1        1     4.0\n",
       "1       5        1     4.0\n",
       "2       7        1     4.5\n",
       "3      15        1     2.5\n",
       "4      17        1     4.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = movies.groupby(by=['userId','movieId'], as_index=False, sort=False).mean()\n",
    "df = df[['userId','movieId','rating']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У библиотеки surprise имеются свои датасеты для работы, но если мы хотим настроить свой, то необходимо ввести ряд параметров и загрузить датасет в тот вид, в котором модели для предсказаний этой библиотеки читали бы данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df, reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сперва мы просто проверяем модель без разделения на train и test и проводим кросс валидацию. Также мы добавили метрику MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8807  0.8721  0.8766  0.8721  0.8741  0.8752  0.0032  \n",
      "MAE (testset)     0.6763  0.6693  0.6692  0.6729  0.6729  0.6721  0.0026  \n",
      "Fit time          5.04    5.00    5.02    5.04    5.00    5.02    0.02    \n",
      "Test time         0.17    0.17    0.13    0.12    0.17    0.15    0.02    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.88074807, 0.87214186, 0.87663364, 0.87214472, 0.87412232]),\n",
       " 'test_mae': array([0.6763057 , 0.66933093, 0.66923478, 0.67292077, 0.67286319]),\n",
       " 'fit_time': (5.035577774047852,\n",
       "  5.000511407852173,\n",
       "  5.018805503845215,\n",
       "  5.040560245513916,\n",
       "  5.002658843994141),\n",
       " 'test_time': (0.17154383659362793,\n",
       "  0.17254018783569336,\n",
       "  0.12783193588256836,\n",
       "  0.12366938591003418,\n",
       "  0.16858220100402832)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, мы получили результаты, наша средняя RMSE - 0.87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь начнем строить модели используя разбивку на train и test и постараемся улучшить ее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8736\n",
      "Wall time: 5.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# используем 25 % данных для тестовой выборки\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "# выбор модели\n",
    "algo = SVD()\n",
    "\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8583\n",
      "Wall time: 8min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from surprise import SVDpp\n",
    "# используем 25 % данных для тестовой выборки\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "# выбор модели\n",
    "algo = SVDpp()\n",
    "\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNNWithMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9000856094605502"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import KNNWithMeans\n",
    "\n",
    "# используем 25 % данных для тестовой выборки\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "# выбор модели\n",
    "algo = KNNWithMeans()\n",
    "\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNNBasic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9582837971278426"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import KNNBasic\n",
    "# используем 25 % данных для тестовой выборки\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "# выбор модели\n",
    "algo = KNNBasic()\n",
    "\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNNBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8770488965989934"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import KNNBaseline\n",
    "\n",
    "# используем 25 % данных для тестовой выборки\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "# выбор модели\n",
    "algo = KNNBaseline()\n",
    "\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9230703013373539"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import NMF\n",
    "# используем 25 % данных для тестовой выборки\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "# выбор модели\n",
    "algo = NMF()\n",
    "\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SlopeOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9005560507751065"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SlopeOne\n",
    "\n",
    "# используем 25 % данных для тестовой выборки\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "# выбор модели\n",
    "algo = SlopeOne()\n",
    "\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9442174494128958"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import CoClustering\n",
    "\n",
    "# используем 25 % данных для тестовой выборки\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "# выбор модели\n",
    "algo = CoClustering()\n",
    "\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNNWithZScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8934450503900331"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import KNNWithZScore\n",
    "\n",
    "# используем 25 % данных для тестовой выборки\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "# выбор модели\n",
    "algo = KNNWithZScore()\n",
    "\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как лучшие результаты были у SVD и SVD++ , мы решили попробовать еще метод, чтобы сделать результаты более точными.Для более точной и объективной оценки, мы воспользовались идеей и примером одного из авторов данной библиотеки. Этот скрипт позволяет разделить выборку на 2 части, где A - это выборка, которая применяется для настройки параметров модели, а B для объективной оценки. Тем самым этот скрипт позволит дать более точную и качественную оценку. Но минус скрипта заключается в том, что модель очень долго строится и просчитывается. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search...\n",
      "Biased accuracy on A,   RMSE: 0.6328\n",
      "Unbiased accuracy on B, RMSE: 0.8705\n",
      "Wall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import random\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Загружаем датасет\n",
    "\n",
    "raw_ratings = data.raw_ratings\n",
    "\n",
    "# перемешка данных\n",
    "random.shuffle(raw_ratings)\n",
    "\n",
    "# A = 80 процентов всех данных, B = 20% всех данных\n",
    "threshold = int(.8 * len(raw_ratings))\n",
    "A_raw_ratings = raw_ratings[:threshold]\n",
    "B_raw_ratings = raw_ratings[threshold:]\n",
    "\n",
    "data.raw_ratings = A_raw_ratings  # набор А\n",
    "\n",
    "# Установка параметров для модели через gridsearch\n",
    "print('Grid Search...')\n",
    "param_grid = {'n_epochs': [5, 10, 30, 50], 'lr_all': [0.002, 0.005]}\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=5)\n",
    "grid_search.fit(data)\n",
    "\n",
    "algo = grid_search.best_estimator['rmse']\n",
    "\n",
    "# Обучим на выборке А \n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Вычислим смещенную точность на выборке А\n",
    "predictions = algo.test(trainset.build_testset())\n",
    "print('Biased accuracy on A,', end='   ')\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "# Вычислим объективную точность на выборке В\n",
    "testset = data.construct_testset(B_raw_ratings)  # Набор\n",
    "predictions = algo.test(testset)\n",
    "print('Unbiased accuracy on B,', end=' ')\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search...\n",
      "Biased accuracy on A,   RMSE: 0.7345\n",
      "Unbiased accuracy on B, RMSE: 0.8591\n",
      "Wall time: 4h 49min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# A = 80 процентов всех данных, B = 20% всех данных\n",
    "threshold = int(.8 * len(raw_ratings))\n",
    "A_raw_ratings = raw_ratings[:threshold]\n",
    "B_raw_ratings = raw_ratings[threshold:]\n",
    "\n",
    "data.raw_ratings = A_raw_ratings  # набор А\n",
    "\n",
    "# Установка параметров для модели через gridsearch\n",
    "print('Grid Search...')\n",
    "param_grid = {'n_epochs': [5, 10, 30, 50], 'lr_all': [0.002, 0.005]}\n",
    "grid_search = GridSearchCV(SVDpp, param_grid, measures=['rmse'], cv=5)\n",
    "grid_search.fit(data)\n",
    "\n",
    "algo = grid_search.best_estimator['rmse']\n",
    "\n",
    "# Обучим на выборке А \n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Вычислим смещенную точность на выборке А\n",
    "predictions = algo.test(trainset.build_testset())\n",
    "print('Biased accuracy on A,', end='   ')\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "# Вычислим объективную точность на выборке В\n",
    "testset = data.construct_testset(B_raw_ratings)  # Набор\n",
    "predictions = algo.test(testset)\n",
    "print('Unbiased accuracy on B,', end=' ')\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведя предсказания используя ряд моделей, мы выявили, что SVD модели лучше всего подходят для нашей подвыборки и лучше всего предсказывают.\n",
    "\n",
    "Результаты без применения GridsearchCV с разибением на train и test split:\n",
    "\n",
    "SVD = 0.8736\n",
    "\n",
    "SVD ++  = 0.8583\n",
    "\n",
    "C применением GridsearchCV и разбиением на 2 подвыборки А и В.\n",
    "\n",
    "SVD\n",
    "\n",
    "Смещенная точность (на выборке A) - 0.6328\n",
    "\n",
    "Объективная точность (на выборке В) - 0.8705\n",
    "\n",
    "SVD++\n",
    "\n",
    "Смещенная точность (на выборке A) - 0.7345\n",
    "\n",
    "Объективная точность (на выборке В) - 0.8591"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И также мы предпологаем, что нашим основным критерием был MSE, а не RMSE. Теперь найдем MSE нашей лучшей модели\n",
    "\n",
    "RMSE = MSE ^ 1/2\n",
    "\n",
    "MSE = RMSE ^ 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73805281"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_R = 0.8591 ** 2\n",
    "MSE_R"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
